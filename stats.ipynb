{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install xlrd openpyxl scikit-learn tqdm torchviz pandas plotly numpy nbformat tqdm torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import tqdm as tqdm\n",
    "import plotly.express as px\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.amp as amp\n",
    "import torchvision.models as models\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "np.version.full_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hope_production_df = pd.read_excel('data.xlsx', sheet_name=\"HOPE PRODUCTION\")\n",
    "hope_storage_df = pd.read_excel('data.xlsx', sheet_name=\"HOPE STORAGE AFTER COOKING\")\n",
    "\n",
    "faith_production_df = pd.read_excel('data.xlsx', sheet_name=\"FAITH PRODUCTION\")\n",
    "faith_storage_df = pd.read_excel('data.xlsx', sheet_name=\"FAITH STORAGE AFTER COOKING\")\n",
    "\n",
    "hope_faith_df = pd.read_excel('data.xlsx', sheet_name=\"HOPE-FAITH PACKAGE WEIGHTS\")\n",
    "hope_faith_df.rename(columns={\n",
    "    x: f\"Sample {i + 1}\" for i, x in \n",
    "    enumerate((x for x in hope_faith_df.columns if \"Unnamed\" in x))}, inplace=True)\n",
    "\n",
    "hope_faith_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hope_df = hope_storage_df.merge(hope_production_df, right_on=[\"BATCH no.\", \"PRODUCTION DATE\"], left_on=[\"BATCH no.\", \"BATCH INTO STORAGE\"])\n",
    "faith_df = faith_storage_df.merge(faith_production_df, right_on=[\"BATCH no.\", \"PRODUCTION DATE\"], left_on=[\"BATCH no.\", \"BATCH INTO STORAGE\"])\n",
    "hope_df[\"PRODUCT\"] = 5409\n",
    "faith_df[\"PRODUCT\"] = 5030\n",
    "\n",
    "HOPE_SHELF_LIFE = 28\n",
    "FAITH_SHELF_LIFE = 30\n",
    "\n",
    "hope_df[\"ESTIMATED EXPIRY\"] = hope_df[\"BATCH INTO STORAGE\"] + pd.Timedelta(days=HOPE_SHELF_LIFE)\n",
    "faith_df[\"ESTIMATED EXPIRY\"] = faith_df[\"BATCH INTO STORAGE\"] + pd.Timedelta(days=FAITH_SHELF_LIFE)\n",
    "\n",
    "hope_pre_df = hope_df.merge(\n",
    "        hope_faith_df, left_on=[\"ESTIMATED EXPIRY\", \"PRODUCT\"], right_on=[\"EXPIRY DATE\", \"PRODUCT\"]\n",
    "    )\n",
    "faith_pre_df = faith_df.merge(\n",
    "        hope_faith_df, left_on=[\"ESTIMATED EXPIRY\", \"PRODUCT\"], right_on=[\"EXPIRY DATE\", \"PRODUCT\"]\n",
    "    )\n",
    "\n",
    "\n",
    "pre_df = pd.concat([hope_pre_df, faith_pre_df])\n",
    "display(pre_df.columns)\n",
    "# TODO: ONE PACKAGE HAS MORE THAN ONE PRODUCT\n",
    "pre_df[\"PRODUCT AMOUNT EXPECTED\"] = [1000 * row[\"BATCH WEIGHT (kg) AFTER COOKING\"] / row[\"AVERAGE WEIGHT (g)\"] for _, row in pre_df.iterrows()]\n",
    "\n",
    "pre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 5\n",
    "OUTPUT_SIZE = 1\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__(self)\n",
    "        INTERNAL = 7\n",
    "        self.l1 = nn.Linear(INPUT_SIZE, INTERNAL)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(INTERNAL, INTERNAL)\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "        self.l3 = nn.Linear(INTERNAL, OUTPUT_SIZE)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.l3(self.lrelu(self.l2(self.relu(self.l1(x)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviations = []\n",
    "\n",
    "for i, row in pre_df.iterrows():\n",
    "    cols = [col for col in pre_df.columns if \"Sample\" in col]\n",
    "    ls = []\n",
    "    for col in cols:\n",
    "        v = row[col]\n",
    "        if np.isnan(v):\n",
    "            continue\n",
    "        ls.append(v)\n",
    "    deviations.append(np.std(ls))\n",
    "\n",
    "len(deviations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>time_in_storage</th>\n",
       "      <th>weekday</th>\n",
       "      <th>input_amount</th>\n",
       "      <th>cooking_out__storage_in</th>\n",
       "      <th>storage_out__packaging_in</th>\n",
       "      <th>product_amount_expected</th>\n",
       "      <th>mean</th>\n",
       "      <th>stdev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.653935</td>\n",
       "      <td>0.610111</td>\n",
       "      <td>0.610111</td>\n",
       "      <td>0.752764</td>\n",
       "      <td>0.031817</td>\n",
       "      <td>3.952847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.653935</td>\n",
       "      <td>0.610111</td>\n",
       "      <td>0.610111</td>\n",
       "      <td>0.759485</td>\n",
       "      <td>0.013522</td>\n",
       "      <td>3.160888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.655252</td>\n",
       "      <td>0.609163</td>\n",
       "      <td>0.609163</td>\n",
       "      <td>0.751597</td>\n",
       "      <td>0.031817</td>\n",
       "      <td>3.952847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.655252</td>\n",
       "      <td>0.609163</td>\n",
       "      <td>0.609163</td>\n",
       "      <td>0.758308</td>\n",
       "      <td>0.013522</td>\n",
       "      <td>3.160888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.656569</td>\n",
       "      <td>0.606951</td>\n",
       "      <td>0.606951</td>\n",
       "      <td>0.748874</td>\n",
       "      <td>0.031817</td>\n",
       "      <td>3.952847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34714</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.828449</td>\n",
       "      <td>0.812954</td>\n",
       "      <td>0.812954</td>\n",
       "      <td>0.695072</td>\n",
       "      <td>0.945912</td>\n",
       "      <td>3.673703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34715</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.818900</td>\n",
       "      <td>0.807899</td>\n",
       "      <td>0.807899</td>\n",
       "      <td>0.699840</td>\n",
       "      <td>0.907254</td>\n",
       "      <td>6.415238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34716</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.818900</td>\n",
       "      <td>0.807899</td>\n",
       "      <td>0.807899</td>\n",
       "      <td>0.690750</td>\n",
       "      <td>0.945912</td>\n",
       "      <td>3.673703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34717</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.540665</td>\n",
       "      <td>0.527330</td>\n",
       "      <td>0.527330</td>\n",
       "      <td>0.456813</td>\n",
       "      <td>0.907254</td>\n",
       "      <td>6.415238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34718</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.540665</td>\n",
       "      <td>0.527330</td>\n",
       "      <td>0.527330</td>\n",
       "      <td>0.450864</td>\n",
       "      <td>0.945912</td>\n",
       "      <td>3.673703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34719 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       product  time_in_storage   weekday  input_amount  \\\n",
       "0            1              0.0  0.500000      0.653935   \n",
       "1            1              0.0  0.500000      0.653935   \n",
       "2            1              0.0  0.500000      0.655252   \n",
       "3            1              0.0  0.500000      0.655252   \n",
       "4            1              0.0  0.500000      0.656569   \n",
       "...        ...              ...       ...           ...   \n",
       "34714        0              3.0  0.666667      0.828449   \n",
       "34715        0              3.0  0.666667      0.818900   \n",
       "34716        0              3.0  0.666667      0.818900   \n",
       "34717        0              2.0  0.666667      0.540665   \n",
       "34718        0              2.0  0.666667      0.540665   \n",
       "\n",
       "       cooking_out__storage_in  storage_out__packaging_in  \\\n",
       "0                     0.610111                   0.610111   \n",
       "1                     0.610111                   0.610111   \n",
       "2                     0.609163                   0.609163   \n",
       "3                     0.609163                   0.609163   \n",
       "4                     0.606951                   0.606951   \n",
       "...                        ...                        ...   \n",
       "34714                 0.812954                   0.812954   \n",
       "34715                 0.807899                   0.807899   \n",
       "34716                 0.807899                   0.807899   \n",
       "34717                 0.527330                   0.527330   \n",
       "34718                 0.527330                   0.527330   \n",
       "\n",
       "       product_amount_expected      mean     stdev  \n",
       "0                     0.752764  0.031817  3.952847  \n",
       "1                     0.759485  0.013522  3.160888  \n",
       "2                     0.751597  0.031817  3.952847  \n",
       "3                     0.758308  0.013522  3.160888  \n",
       "4                     0.748874  0.031817  3.952847  \n",
       "...                        ...       ...       ...  \n",
       "34714                 0.695072  0.945912  3.673703  \n",
       "34715                 0.699840  0.907254  6.415238  \n",
       "34716                 0.690750  0.945912  3.673703  \n",
       "34717                 0.456813  0.907254  6.415238  \n",
       "34718                 0.450864  0.945912  3.673703  \n",
       "\n",
       "[34719 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['product'] = le.fit_transform(pre_df['PRODUCT'])\n",
    "\n",
    "df['time_in_storage'] = [x / np.timedelta64(1, 'D') for x in (pre_df[\"BATCH OUT OF STORAGE\"] - pre_df[\"BATCH INTO STORAGE\"]).values]\n",
    "df['weekday'] = [x.weekday() for x in pre_df[\"BATCH INTO STORAGE\"]]\n",
    "df['weekday'] = df['weekday'] / max(df['weekday'])\n",
    "df['input_amount'] = preprocessing.MinMaxScaler().fit_transform(pre_df[\"BATCH WEIGHT (kg) BEFORE COOKING\"].values.reshape(-1, 1))\n",
    "df['cooking_out__storage_in'] = preprocessing.MinMaxScaler().fit_transform(pre_df[\"BATCH WEIGHT (kg) AFTER COOKING\"].values.reshape(-1, 1))\n",
    "df['storage_out__packaging_in'] = preprocessing.MinMaxScaler().fit_transform(pre_df[\"BATCH WEIGHT LEAVING STORAGE (KG)\"].values.reshape(-1, 1))\n",
    "df['product_amount_expected'] = preprocessing.MinMaxScaler().fit_transform(pre_df[\"PRODUCT AMOUNT EXPECTED\"].values.reshape(-1, 1))\n",
    "df['mean'] = preprocessing.MinMaxScaler().fit_transform(pre_df[\"AVERAGE WEIGHT (g)\"].values.reshape(-1, 1))\n",
    "df['stdev'] = deviations\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = df\n",
    "        self.target = [\"input_amount\",\"cooking_out__storage_in\",\"storage_out__packaging_in\"] \n",
    "        \n",
    "        x_data, y_data = [], []\n",
    "        for _, row in self.data.iterrows():\n",
    "            x_row, y_row = [], []\n",
    "            for k, v in row.items():\n",
    "                if k in self.target:\n",
    "                    y_row.append(v)\n",
    "                else:\n",
    "                    x_row.append(v)\n",
    "            x_data.append(x_row)\n",
    "            y_data.append(y_row)\n",
    "\n",
    "        self.x_tensor = torch.tensor(x_data, dtype=torch.float32, device='cuda')\n",
    "        self.y_tensor = torch.tensor(y_data, dtype=torch.float32, device='cuda')\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        return self.x_tensor[index], self.y_tensor[index]\n",
    "        \n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "data = Data()\n",
    "\n",
    "def loader(data):\n",
    "    return DataLoader(\n",
    "        data,\n",
    "        batch_size=64,\n",
    "        shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = len(data[0][0])\n",
    "OUTPUT_SIZE = len(data[0][1])\n",
    "INTERNAL = 16\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = nn.Linear(INPUT_SIZE, INTERNAL)\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "        self.l2 = nn.Linear(INTERNAL, INTERNAL)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l3 = nn.Linear(INTERNAL, INTERNAL)\n",
    "        self.silu = nn.SiLU()\n",
    "        self.l4 = nn.Linear(INTERNAL, INTERNAL)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.l5 = nn.Linear(INTERNAL, OUTPUT_SIZE)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.l5(self.relu2(self.l4(self.silu(self.l3(self.relu(self.l2((self.lrelu(self.l1(x))))))))))\n",
    "\n",
    "INPUT_SIZE, INTERNAL, INTERNAL, INTERNAL, OUTPUT_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = torch.utils.data.random_split(data, [.8, .2])\n",
    "train_dataset = loader(train_dataset)\n",
    "display(train_dataset)\n",
    "display(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "device.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scaler = torch.amp.GradScaler(device.type)\n",
    "epochs = 22  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm.tqdm(range(epochs)):\n",
    "    for j, (x_train, y_train) in enumerate(train_dataset):\n",
    "        with torch.amp.autocast(device_type='cuda'):\n",
    "            y_pred = model(x_train)\n",
    "            cost = criterion(y_pred, y_train)\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        scaler.scale(cost).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    if i % 10 == 0:\n",
    "        torch.save(model, f\"out2/model-{i}.pt\")\n",
    "\n",
    "torch.save(model, \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model.pt')\n",
    "model.eval()\n",
    "\n",
    "losses = []\n",
    "with torch.no_grad():\n",
    "    for i, (x, y) in enumerate(test_dataset):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_pred = model(x).to(device)\n",
    "        loss = criterion(y_pred, y)\n",
    "        losses.append(loss.cpu())\n",
    "\n",
    "loss_df = pd.DataFrame(dict(losses=losses))\n",
    "\n",
    "fig = px.scatter(loss_df, x=\"losses\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([1 for l in losses if l > 0.1]) / len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
