{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install xlrd openpyxl scikit-learn tqdm torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import tqdm as tqdm\n",
    "\n",
    "np.version.full_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hope_production_df = pd.read_excel('data.xlsx', sheet_name=\"HOPE PRODUCTION\")\n",
    "hope_storage_df = pd.read_excel('data.xlsx', sheet_name=\"HOPE STORAGE AFTER COOKING\")\n",
    "\n",
    "faith_production_df = pd.read_excel('data.xlsx', sheet_name=\"FAITH PRODUCTION\")\n",
    "faith_storage_df = pd.read_excel('data.xlsx', sheet_name=\"FAITH STORAGE AFTER COOKING\")\n",
    "\n",
    "hope_faith_df = pd.read_excel('data.xlsx', sheet_name=\"HOPE-FAITH PACKAGE WEIGHTS\")\n",
    "hope_faith_df.rename(columns={\n",
    "    x: f\"Sample {i + 1}\" for i, x in \n",
    "    enumerate((x for x in hope_faith_df.columns if \"Unnamed\" in x))}, inplace=True)\n",
    "\n",
    "hope_faith_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hope_df = hope_storage_df.merge(hope_production_df, right_on=[\"BATCH no.\", \"PRODUCTION DATE\"], left_on=[\"BATCH no.\", \"BATCH INTO STORAGE\"])\n",
    "faith_df = faith_storage_df.merge(faith_production_df, right_on=[\"BATCH no.\", \"PRODUCTION DATE\"], left_on=[\"BATCH no.\", \"BATCH INTO STORAGE\"])\n",
    "hope_df[\"PRODUCT\"] = 5409\n",
    "faith_df[\"PRODUCT\"] = 5030\n",
    "\n",
    "HOPE_SHELF_LIFE = 28\n",
    "FAITH_SHELF_LIFE = 30\n",
    "\n",
    "hope_df[\"ESTIMATED EXPIRY\"] = hope_df[\"BATCH INTO STORAGE\"] + pd.Timedelta(days=HOPE_SHELF_LIFE)\n",
    "faith_df[\"ESTIMATED EXPIRY\"] = faith_df[\"BATCH INTO STORAGE\"] + pd.Timedelta(days=FAITH_SHELF_LIFE)\n",
    "\n",
    "hope_pre_df = hope_df.merge(\n",
    "        hope_faith_df, left_on=[\"ESTIMATED EXPIRY\", \"PRODUCT\"], right_on=[\"EXPIRY DATE\", \"PRODUCT\"]\n",
    "    )\n",
    "faith_pre_df = faith_df.merge(\n",
    "        hope_faith_df, left_on=[\"ESTIMATED EXPIRY\", \"PRODUCT\"], right_on=[\"EXPIRY DATE\", \"PRODUCT\"]\n",
    "    )\n",
    "\n",
    "\n",
    "pre_df = pd.concat([hope_pre_df, faith_pre_df])\n",
    "display(pre_df.columns)\n",
    "pre_df[\"PRODUCT AMOUNT EXPECTED\"] = [1000 * row[\"BATCH WEIGHT (kg) AFTER COOKING\"] / row[\"AVERAGE WEIGHT (g)\"] for _, row in pre_df.iterrows()]\n",
    "\n",
    "pre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 5\n",
    "OUTPUT_SIZE = 1\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__(self)\n",
    "        INTERNAL = 7\n",
    "        self.l1 = nn.Linear(INPUT_SIZE, INTERNAL)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(INTERNAL, INTERNAL)\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "        self.l3 = nn.Linear(INTERNAL, OUTPUT_SIZE)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.l3(self.lrelu(self.l2(self.relu(self.l1(x)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['product'] = le.fit_transform(pre_df['PRODUCT'])\n",
    "\n",
    "df['time_in_storage'] = [x / np.timedelta64(1, 'D') for x in (pre_df[\"BATCH OUT OF STORAGE\"] - pre_df[\"BATCH INTO STORAGE\"]).values]\n",
    "df['input_amount'] = preprocessing.MinMaxScaler().fit_transform(pre_df[\"BATCH WEIGHT (kg) BEFORE COOKING\"].values.reshape(-1, 1))\n",
    "df['cooking_out__storage_in'] = preprocessing.MinMaxScaler().fit_transform(pre_df[\"BATCH WEIGHT (kg) AFTER COOKING\"].values.reshape(-1, 1))\n",
    "df['storage_out__packaging_in'] = preprocessing.MinMaxScaler().fit_transform(pre_df[\"BATCH WEIGHT LEAVING STORAGE (KG)\"].values.reshape(-1, 1))\n",
    "df['product_amount_expected'] = preprocessing.MinMaxScaler().fit_transform(pre_df[\"PRODUCT AMOUNT EXPECTED\"].values.reshape(-1, 1))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = df\n",
    "        self.target = [\"input_amount\"]\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        row = self.data.iloc[index]\n",
    "        x = []\n",
    "        y = []\n",
    "        for k, v in row.items():\n",
    "            if k in self.target:\n",
    "                y.append(v)\n",
    "            else:\n",
    "                x.append(v)\n",
    "        return tuple(map(torch.Tensor, [x, y]))\n",
    "\n",
    "data = Data()\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = len(data[0][0])\n",
    "OUTPUT_SIZE = len(data[0][1])\n",
    "INTERNAL = 7\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = nn.Linear(INPUT_SIZE, INTERNAL)\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "        self.l2 = nn.Linear(INTERNAL, INTERNAL)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l3 = nn.Linear(INTERNAL, OUTPUT_SIZE)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.l3(self.relu(self.l2((self.lrelu(self.l1(x))))))\n",
    "\n",
    "INPUT_SIZE, INTERNAL, OUTPUT_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = torch.utils.data.random_split(data, [.8, .2])\n",
    "\n",
    "display(train_dataset)\n",
    "display(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scaler = torch.amp.GradScaler(device.type)\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm.tqdm(range(epochs)):\n",
    "    for j, (x_train, y_train) in enumerate(train_dataset):\n",
    "        x_train = x_train.to(device)\n",
    "        y_train = y_train.to(device)\n",
    "\n",
    "        with torch.amp.autocast(device_type=device.type):\n",
    "            y_pred = model(x_train)\n",
    "            cost = criterion(y_pred, y_train)\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        scaler.scale(cost).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    if i % 1 == 0:\n",
    "        torch.save(model, f\"model-{j}.pt\")\n",
    "\n",
    "torch.save(model, \"model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
